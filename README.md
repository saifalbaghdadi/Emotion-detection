# Emotion detection Project

<img src=https://raw.githubusercontent.com/saifalbaghdadi/Emotion-detection/main/templates/img/1.jpg?token=GHSAT0AAAAAABTSUXQ62BES6QRGHNZGHI6KYV5XFNQ height="200">

## Mission objectives

- Be able to analyze and classify images of faces according to the facial-expression.
- Be able to analyze real-time images (video streaming) and implement facial-expression recognition.
- Explore techniques to identify emotions from subtle movements or gestures on the face.

## The Mission

An important global firm receives thousands of job applications every year. However, the HR team does not have
enough time to review each one of the applications. This is the reason why they are looking for innovative solutions
to be integrated into the selection and recruitment process.

Looking to accelerate the interview pace, the company is investing resources in a video-interview system where pre-defined questions are asked by a virtual HR agent. In some jobs, personality is an important asset and the company would like to automatically analyze the images from the video footage, quantify the emotions expressed by the job applicants, and select the appropriate candidate according to the open job opportunities. They want to take it a step further, detecting a smile or sad face is not enough. They want a tool capable of recognizing even subtle changes in facial expression that might
indicate a particular emotion.

![Emotions (GIF)](https://media.giphy.com/media/84rG9j2H62hwc/giphy.gif)


### Must-have features

- As a minimum valuable product, the model should be able to identify human expressions such as happiness and sadness.
- Explore ways to detect more complex emotions.
- Deployment of the tool or integration with platforms is highly encouraged.

### Miscellaneous information

Some datasets are provided as initial material helpful to train or test your models. However, take the time to think
about the limitations that might be attached to the provided data and explore the possibility of using more datasets
or technologies adapted to the problem you are trying to solve.

### Dataset

- [FER-2013](https://www.kaggle.com/msambare/fer2013)


## Technical Evaluation criteria

- Ability to recognize sadness and happiness in images.
- Ability to recognize more complex emotions in images.
- Ability to recognize emotions in videos.
- A baseline model was established.
- Appropiate metrics were used to evaluate the model.
- Preprocessing of the images was done to improve detection.
- Model was deployed using Streamlit, Flask, and/or Heroku.


