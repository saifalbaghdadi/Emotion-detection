{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3744dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb211375",
   "metadata": {},
   "source": [
    "### Analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297340bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dataset\n",
    "\n",
    "train_dir = '../data/train/'\n",
    "test_dir = '../data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef246d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(img_dir, top=10):\n",
    "    all_img_dirs = os.listdir(img_dir)\n",
    "    img_files = [os.path.join(img_dir, file) for file in all_img_dirs][:5]\n",
    "    plt.figure(figsize=(10, 10))  \n",
    "    for idx, img_path in enumerate(img_files):\n",
    "        plt.subplot(5, 5, idx+1)\n",
    "        img = plt.imread(img_path)\n",
    "        plt.tight_layout()        \n",
    "        plt.axis('off')\n",
    "        plt.imshow(img, cmap='gray') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ef908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANGRY\n",
    "plot_images(train_dir+'/angry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b0802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISGUSTED\n",
    "plot_images(train_dir+'/disgust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89092666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEARFUL\n",
    "plot_images(train_dir+'/fear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2354d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAPPY\n",
    "plot_images(train_dir+'/happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadc9851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEUTRAL\n",
    "plot_images(train_dir+'/neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d4ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAD\n",
    "plot_images(train_dir+'/sad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f060fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SURPRISED\n",
    "plot_images(train_dir+'/surprise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089b697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_chart_diagram(path_data):\n",
    "  dic={}\n",
    "  for emotion in  os.listdir(path_data):\n",
    "    dem=0\n",
    "    for x in os.listdir(path_data+\"/\"+emotion):\n",
    "      dem+=1\n",
    "    dic[emotion]=dem\n",
    "  print(dic)\n",
    "  barlist=plt.bar(range(len(dic)), list(dic.values()),tick_label=list(dic.keys()))\n",
    "#set color\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6080ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_chart_diagram(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e14cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_chart_diagram(test_dir)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1335b897",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a47bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training and Validation Batches by Using the ImageDataGenerator\n",
    "\n",
    "img_size = 48\n",
    "batch_size = 64\n",
    "\n",
    "data_train = ImageDataGenerator(horizontal_flip=True)\n",
    "train_generator = data_train.flow_from_directory(train_dir, target_size=(img_size,img_size), color_mode=\"grayscale\",\n",
    "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "\n",
    "data_validation = ImageDataGenerator(horizontal_flip=True)\n",
    "validation_generator = data_validation.flow_from_directory(test_dir, target_size=(img_size,img_size), color_mode=\"grayscale\",\n",
    "                                                    batch_size=batch_size, class_mode='categorical', shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf5075",
   "metadata": {},
   "source": [
    "### Create Convolutional Nueral Network (CNN) Model\n",
    "Create a Nueral Network using 4 Convolutional Layers and 2 Fully Connected dense Layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da2154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f592b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st Convolution Layer\n",
    "\n",
    "# There are 64 (3,3) filters with \"same\" Padding and Shape of the Input_Image is (48,48,1)\n",
    "model.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,1)))\n",
    "\n",
    "# Normalizing to speed up learning.\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Applying Non Linear Activation Function \"relu\"\n",
    "model.add(Activation('relu'))  \n",
    "\n",
    "# Adding a Max Pool Layer of size (2,2)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout layer with 0.25 fraction of the input units to drop\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9808934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd Convolution layer\n",
    "\n",
    "# There are 128 (5,5) filters with \"same\" Padding \n",
    "model.add(Conv2D(128,(5,5), padding='same'))\n",
    "\n",
    "# Normalizing to speed up learning.\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Applying Non Linear Activation Function \"relu\"\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Adding a Max Pool Layer of size (2,2)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout layer with 0.25 fraction of the input units to drop\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b7e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd Convolution layer\n",
    "\n",
    "# There are 512 (3,3) filters with \"same\" Padding \n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "\n",
    "# Normalizing to speed up learning.\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Applying Non Linear Activation Function \"relu\"\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Adding a Max Pool Layer of size (2,2)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout layer with 0.25 fraction of the input units to drop\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th Convolution layer\n",
    "\n",
    "# There are 512 (3,3) filters with \"same\" Padding \n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "\n",
    "# Normalizing to speed up learning.\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Applying Non Linear Activation Function \"relu\"\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Adding a Max Pool Layer of size (2,2)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout layer with 0.25 fraction of the input units to drop \n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af38421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with 256 nuerons\n",
    "model.add(Dense(256))\n",
    "\n",
    "# Normalizing to speed up learning.\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Applying Non Linear Activation Function \"relu\"\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Dropout layer with 0.25 fraction of the input units to drop\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# Fully connected layer with 512 nuerons\n",
    "model.add(Dense(512))\n",
    "\n",
    "# Normalizing to speed up learning.\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Applying Non Linear Activation Function \"relu\"\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Dropout layer with 0.25 fraction of the input units to drop\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Adding a final Dense Layer with 7 outputs corresponding to 7 different emotions with a \"softmax\" Activation Function \n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8656cb10",
   "metadata": {},
   "source": [
    "### Compiling the Model\n",
    "use Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam is an optimization algorithm that can be used instead of the classical stochastic gradient descent \n",
    "# procedure to update network weights iterative based in training data.\n",
    "\n",
    "# choose a Learning rate of 0.0005 \n",
    "opt = Adam(learning_rate=0.0005)\n",
    "\n",
    "# Compile defines the loss function, the optimizer and the metrics.\n",
    "\n",
    "# As I have Categorical Values we will use 'categorical_crossentropy' loss function\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# check the details of the Model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab0c028",
   "metadata": {},
   "source": [
    "### Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc01cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because my computer is not powerful, I will use the training for 15 epochs and that takes (15+ minutes for each one epoch)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "steps_per_epoch = train_generator.n//train_generator.batch_size\n",
    "validation_steps = validation_generator.n//validation_generator.batch_size\n",
    "\n",
    "# Create a Callback which reduces the Learning rate by a factor of \"0.1\" when the val_loss does not decrease\n",
    "# after 2 epochs also and allowing the minimum value of Learning Rate to be 0.00001\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=2, min_lr=0.00001, mode='auto')\n",
    "\n",
    "# Create another Callback which saves the Model Weights by monitoring the Val_Accuracy\n",
    "checkpoint = ModelCheckpoint(\"../model/model_weights.h5\", monitor='val_accuracy',\n",
    "                             save_weights_only=True, mode='max', verbose=1)\n",
    "\n",
    "# A callback is an object that can perform actions at various stages of training\n",
    "callbacks = [checkpoint, reduce_lr]\n",
    "\n",
    "# Fitting the model\n",
    "history = model.fit( x=train_generator, steps_per_epoch=steps_per_epoch,\n",
    "                     epochs=epochs, validation_data = validation_generator,\n",
    "                     validation_steps = validation_steps, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "save_model(model,'../model/model_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a3a295",
   "metadata": {},
   "source": [
    "#### Loss and Accuracy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7452ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Train History\n",
    "keys=history.history.keys()\n",
    "print(keys)\n",
    "\n",
    "def show_train_history(hisData,train,test): \n",
    "    plt.plot(hisData.history[train])\n",
    "    plt.plot(hisData.history[test])\n",
    "    plt.title('Training History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "show_train_history(history, 'loss', 'val_loss')\n",
    "show_train_history(history, 'accuracy', 'val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b6b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "\n",
    "train_loss, train_acc = model.evaluate(train_generator)\n",
    "test_loss, test_acc   = model.evaluate(validation_generator)\n",
    "print(\"final train accuracy = {:.2f} , validation accuracy = {:.2f}\".format(train_acc*100, test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7576e64a",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd110bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "img = image.load_img(\"../static/ImgTest/test1.png\",target_size = (48,48),color_mode = \"grayscale\")\n",
    "img = np.array(img)\n",
    "plt.imshow(img)\n",
    "print(img.shape)    #prints (48,48) that is the shape of our image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2177f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {0:'Angry',1:'Disgust',2:'Fear',3:'Happy',4:'Neutral',5:'Sad',6:'Surprise'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12bc70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes image shape (1,48,48)\n",
    "img = np.expand_dims(img,axis = 0) \n",
    "img = img.reshape(1,48,48,1)\n",
    "result = model.predict(img)\n",
    "result = list(result[0])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53568ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index = result.index(max(result))\n",
    "print(label_dict[img_index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3420eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save Final Model\n",
    "model.save('model_optimal.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492c8ecc",
   "metadata": {},
   "source": [
    "### Represent Model as JSON String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cec77aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the model into JSON format and storing it in \"model.json\" file.\n",
    "model_json = model.to_json()\n",
    "with open(\"../model/model_json.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d217f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1416.158745,
   "end_time": "2022-02-11T11:16:41.353499",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-11T10:53:05.194754",
   "version": "2.3.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "4abe8f0d43810da8e0599c92fa77ff1bc3ba49df42db1369ea5b9c66bb667179"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
